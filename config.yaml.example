matrix:
  homeserver: https://matrix.org          # Your Matrix homeserver URL
  user_id: "@bot:matrix.org"              # Full Matrix user ID of the bot account
  access_token: "YOUR_MATRIX_ACCESS_TOKEN"
  room_id: "!ROOMID:matrix.org"           # Room or DM to listen in

llm:
  # Any OpenAI-compatible endpoint. Examples:
  #   Ollama local:   http://localhost:11434/v1
  #   vLLM:          http://localhost:8000/v1
  #   LM Studio:     http://localhost:1234/v1
  #   OpenAI:        https://api.openai.com/v1
  base_url: "http://localhost:11434/v1"
  api_key: "ollama"                        # Use "ollama" for Ollama, actual key for OpenAI etc.
  model: "qwen2.5:72b"                     # Any model name the endpoint accepts
  max_tokens: 4096
  # Optional: use a smaller/faster model for context compaction summarisation.
  # Falls back to `model` if not set.
  compaction_model: "qwen2.5:7b"

heartbeat:
  review_interval_minutes: 60             # How often to auto-review HEARTBEATS.txt

context:
  compaction_threshold_chars: 150000      # Trigger compaction above this many chars
  component_size_limits:
    memories: 10000                       # Chars before MEMORIES.txt gets summarised
    heartbeats: 5000                      # Chars before HEARTBEATS.txt gets summarised
    skills_total: 20000                   # Total chars across all skills before reorganise

scheduler:
  timezone: "UTC"                         # Timezone for reminder scheduling (e.g. Europe/Berlin)

logging:
  level: "INFO"                           # DEBUG | INFO | WARN | ERROR
  directory: "logs"
